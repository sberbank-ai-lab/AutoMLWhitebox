{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "\n",
    "from collections import OrderedDict\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "\n",
    "from autowoe import ReportDeco, AutoWoE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Чтение и подготовка обучающей выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./example_data/train_demo.csv\",\n",
    "                    low_memory=False,\n",
    "                    index_col=\"line_id\",\n",
    "                    parse_dates = [\"datetime_\" + str(i) for i in range(2)],)\n",
    "\n",
    "train = train.iloc[:, 50:100]\n",
    "\n",
    "num_col = list(filter(lambda x: \"numb\" in x, train.columns))\n",
    "num_feature_type = {x: \"real\" for x in num_col}\n",
    "\n",
    "date_col = filter(lambda x: \"datetime\" in x, train.columns)\n",
    "for col in date_col:\n",
    "    train[col + \"_year\"] = train[col].map(lambda x: x.year)\n",
    "    train[col + \"_weekday\"] = train[col].map(lambda x: x.weekday())\n",
    "    train[col + \"_month\"] = train[col].map(lambda x: x.month)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Чтение и подготовка тестовой выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"./example_data/test_demo.csv\",\n",
    "                   index_col=\"line_id\", \n",
    "                   parse_dates = [\"datetime_\" + str(i) for i in range(2)])\n",
    "\n",
    "date_col = filter(lambda x: \"datetime\" in x, test.columns)\n",
    "for col in date_col:\n",
    "    test[col + \"_year\"] = test[col].map(lambda x: x.year)\n",
    "    test[col + \"_weekday\"] = test[col].map(lambda x: x.weekday())\n",
    "    test[col + \"_month\"] = test[col].map(lambda x: x.month)\n",
    "    \n",
    "test_target = pd.read_csv(\"./example_data/test-target_demo.csv\")[\"target\"]\n",
    "test[\"target\"] = test_target.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Параметры модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для обучения модели рекомендуется указать тип признаков для обучения.\n",
    "Поэтому создается словарь features_type с ключами: \n",
    "\n",
    "\n",
    "\"real\" -- вещественный признак,\n",
    "\n",
    "\"cat\" --  категориальный.\n",
    "\n",
    "Для признаков, которые не размечены, типы будут определены автоматом. Такой вариант будет работать, но качество порядочно просядет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### features_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col = list(filter(lambda x: \"str\" in x, train.columns))\n",
    "cat_feature_type = {x: \"cat\" for x in cat_col}\n",
    "\n",
    "year_col = list(filter(lambda x: \"_year\" in x, train.columns))\n",
    "year_feature_type = {x: \"cat\" for x in year_col}\n",
    "\n",
    "weekday_col = list(filter(lambda x: \"_weekday\" in x, train.columns))\n",
    "weekday_feature_type = {x: \"cat\" for x in weekday_col}\n",
    "\n",
    "month_col = list(filter(lambda x: \"_month\" in x, train.columns))\n",
    "month_feature_type = {x: \"cat\" for x in month_col}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = cat_col + year_col + weekday_col + month_col + num_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature level constrains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_type = dict(**num_feature_type,\n",
    "                     **cat_feature_type,\n",
    "                     **year_feature_type,\n",
    "                     **weekday_feature_type,\n",
    "                     **month_feature_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `features_monotone_constraints` - также можно указать зависимость целевой переменной от признака. Если заранее известно, что при возрастании признака feature_1, то эту информацию можно учесть в модели, добавив в словарь пару {feature_1: \"1\"}. Если же зависимость признака от целевой переменной обратная, то можно указать {feature_1: \"-1\"} Если про зависимость ничего неизвестно, но хочется, чтобы она была монотонная, можно указать 'auto'. Можно указать  {feature_1: \"0\"}, в случае, если установлено общее ограничение на монотонность, чтобы не распространять его на эту фичу. Если специальных условий нет, то можно не собирать этот дикт\n",
    "\n",
    "\n",
    "Рекомендуемое использование:\n",
    "\n",
    "1) В случае, если задано общее условие на монотонность, то можно собрать дикт {feature_1: \"0\", feature_2: \"0\"}, чтобы игнорировать это ограничение для признаков feature_1, feature_2\n",
    "\n",
    "2) В случае, если не задано общее условие на монотонность, то можно собрать дикт {feature_1: \"auto\", feature_2: \"auto\"}, чтобы установить это ограничение для признаков feature_1, feature_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_monotone_constraints = {'number_74': 'auto',  'number_83': 'auto'} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `max_bin_count`  - через словарь max_bin_count можно задать число бинов для WoE кодирования, если для какого-то признака оно отлично от общего. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_bin_count = {'number_47': 3, 'number_51': 2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Рекомендация\n",
    "В общем случае, в первый момент построения модели лучше не указывать специальных ограничений в features_monotone_constraints и max_bin_count. Если в результате анализа полученной модели разбиение оказалось неинтерпретируемым или нестабильным по отдельным признакам, но в целом по модели ок, то ограничить сложность разбиения отдельных призаков имеет смысл. Если разбивка большинства признаков в модели оказалась неудовлетворительная, то рекомендуется в первую очередь настраивать глобальные ограничения (см параметры модели max_bin_count, monotonic, min_bin_size и др ниже)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Общие параметры модели\n",
    "\n",
    "- `interpreted_model` - требуется ли интерпретируемость модели (условие на знак в коэффициентах логистической регрессии)\n",
    "\n",
    "- `monotonic` - Глобальное условие на монотонность. Если указано True, то для всех признаков по умолчанию будут строится только монотонные разбиения. Указать специальные условия для отдельных признаков можно используя features_monotone_constraints аргумент метода .fit\n",
    "\n",
    "- `max_bin_count` - Глобальное ограничение на число бинов. Указать специальные условия для отдельных признаков можно используя max_bin_count аргумент метода .fit\n",
    "\n",
    "- `select_type`  - способ ПРЕДВАРИТЕЛЬНОГО!!! (ЭТО ВАЖНО) отбора признаков. Если указать None, то будут отобраны признаки, у которых importance больше imp_th. Если указвать, например 50, то после предварительного отобра останется только 50 признаков самых важных признаков. Крайне не рекомендуется сильно ограничивать\n",
    "\n",
    "- `pearson_th` - пороговое значение для корреляции Пирсона. Используется на финальной стадии отбора признаков.\n",
    "Если корреляция вух признаков по модулю больше pearson_th, то будет выброшен тот, у которого \n",
    "информативность меньше\n",
    "\n",
    "- `auc_th` - пороговое значение для одномерной оценки качества признака\n",
    "\n",
    "- `vif_th` - пороговое значение для VIF признака\n",
    "\n",
    "- `imp_th` - порог по которому будет произведен отбор признаков, если указать select_type=None (см. ниже).\n",
    "\n",
    "- `th_const` порог по которому признак будет считаться константным. Все константные признаки в модели не учитываются. Если число валидных значений больше трешхолда, то колонка не константная (int). В случае указания float, трешхолд будет определяться как размер_выборки * th_const\n",
    "\n",
    "- `force_single_split` - иногда в силу ограничений на min_bin_size невозможно построить ни одной группировки на переменную. force_single_split=True заставит в этом случае построить единственно возмоджный сплит, в случае если при этом выделяется группа размера более чем th_const. False будет выкидывать этот признак\n",
    "\n",
    "\n",
    "- `th_nan` - порог по которому будет выделена отдельная категория для пропусков в данных.\n",
    "Если число пропусков меньше чем th_nan, то WoE значения для пропусков берется равным нулю.\n",
    "В противном случае пропущенные значения будут выделены в отдельную группу и для них отдельно\n",
    "будет рассчитано WoE значение.\n",
    "Так же влияет на редкие категории (менее th_cat). Если суммарно таких категорий будет менее th_nan, то обработка будет производиться по принципу отпределенному в `cat_merge_to`, иначе оценено по группе\n",
    "\n",
    "- `th_cat` - порог, по которой немногочисленные категории в категориальных признаках будут объединятся в отдельную группу\n",
    "\n",
    "\n",
    "- `woe_diff_th` - Возмодность смеджить наны и редкие категории с каким-то бином, если разница в вое менее woe_diff_th\n",
    "\n",
    "\n",
    "- `min_bin_size` - минимальный размер бина при группировке. Возможно int как число наблюдений и float как доля от выбрки\n",
    "\n",
    "- `min_bin_mults` - в ходе построения бинов будут протестированы возможные значения min_bin_size, \n",
    "min_bin_size * min_bin_mults[0], min_bin_size * min_bin_mults[1] ... . Ждем float > 1. Дефолт - (2, 4), в принципе можно не трогать\n",
    "\n",
    "- `min_gains_to_split` - возможные значения регуляризатора, которые будут протестированы в ходе построения биннинга\n",
    "\n",
    "\n",
    "- `auc_tol` - Чувствительность к AUC. Считаем, что можем пожертвовать auc_tol качества от максимального, чтобы сделать модель проще\n",
    "\n",
    "\n",
    "- `cat_alpha` - Регуляризатор для кодировщика категорий\n",
    "\n",
    "\n",
    "\n",
    "- `cat_merge_to` - группа для редких (менее th_cat) категорий либо новых на тесте\n",
    "         \"to_nan\" -- в группу nan, \n",
    "         \"to_woe_0\" -- отдельная группа с WoE = 0,\n",
    "         \"to_maxfreq\" - в самую большую группу,\n",
    "         \"to_maxp\" - в группу с наибольшей вероятностью события,\n",
    "         \"to_minp\" - в группу с наименьшей вероятностью события\n",
    "         \n",
    "- `nan_merge_to` - группа для НаНов\n",
    "         \"to_woe_0\" -- отдельная группа с WoE = 0,\n",
    "         \"to_maxfreq\" - в самую большую группу,\n",
    "         \"to_maxp\" - в группу с наибольшей вероятностью события,\n",
    "         \"to_minp\" - в группу с наименьшей вероятностью события  \n",
    "         \n",
    "         \n",
    "- `oof_woe` - если указать oof_woe=True, то WoE кодирование будет происходить по кросс-валидации. Если же False, то сразу на всей обучающей выборке.\n",
    "\n",
    "- `n_folds` - количество фолдов для внутренней кроссвалидации\n",
    "\n",
    "\n",
    "- `n_jobs` - число процессов, которое будет использовать модель \n",
    "\n",
    "- `l1_grid_size` - в данной модели на одном из шагов используется отбор признаков LASSO. l1_base_step -- размер сетки для перебора C\n",
    "\n",
    "- `l1_exp_scale` - шкала сетки для L1 отбора. 4 соответствует макс значению C порядка 3-4. Увеличивать, если необходимо сделать менее регуляризованную модель\n",
    "\n",
    "- `imp_type` - способ определения значимости признаков -- features importance (\"feature_imp\" - в общем случае более сложная модель) или permutation importance (\"perm_imp\" - в общем случае более простая модель)\n",
    "\n",
    "- `regularized_refit` - после отбора признаков полученная модель пересчитывается на всех данных. Стоит ли включать L1 при этом. Если нет, то в интерпретируемом режиме модель будет итеративно переобучаться, пока все веса не станут отрицательны. Если да - то аналогичное будет получаться закручиванием L1. Может быть полезно ставить False если нужна стат модель, те p-value на оценки\n",
    "\n",
    "- `p_val` - допустимый уровень p_value на оценки модели при условии обучении стат модели (regularized_refit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_woe = AutoWoE(interpreted_model=True,\n",
    "                     monotonic=False,\n",
    "                     max_bin_count=5,\n",
    "                     select_type=None,\n",
    "                     pearson_th=0.9,\n",
    "                     auc_th=.505,\n",
    "                     vif_th=10.,\n",
    "                     imp_th=0,\n",
    "                     th_const=32,\n",
    "                     force_single_split=True,\n",
    "                     th_nan=0.01,\n",
    "                     th_cat=0.005,\n",
    "                     woe_diff_th=0.01,\n",
    "                     min_bin_size=0.01,\n",
    "                     min_bin_mults=(2, 4),\n",
    "                     min_gains_to_split=(0.0, 0.5, 1.0),\n",
    "                     auc_tol=1e-4,\n",
    "                     cat_alpha=100,\n",
    "                     cat_merge_to=\"to_woe_0\",\n",
    "                     nan_merge_to=\"to_woe_0\",\n",
    "                     oof_woe=True,\n",
    "                     n_folds=6,\n",
    "                     n_jobs=4,\n",
    "                     l1_grid_size=20,\n",
    "                     l1_exp_scale=6,\n",
    "                     imp_type=\"feature_imp\",\n",
    "                     regularized_refit=False,\n",
    "                     p_val=0.05,\n",
    "                     debug=False,\n",
    "                     verbose=0\n",
    "        )\n",
    "\n",
    "auto_woe = ReportDeco(auto_woe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `train` обучающая выборка\n",
    "\n",
    "- `target_name` - название целевой переменной\n",
    "\n",
    "- `features_type` - см выше описание дикта features_type. Возможно указание None для автозаполнения, но не рекомендуется\n",
    "\n",
    "- `group_kf` -  название колонки-группы для GroupKFold https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupKFold.html\n",
    "\n",
    "- `max_bin_count` - см выше описание дикта max_bin_count. Можно ничего не передавать, если специальных условий не предусмотрено. Общее для всех условние задано в __init__\n",
    "\n",
    "- `features_monotone_constraints` - см выше описание дикта features_monotone_constraints. Можно ничего не передавать, если специальных условий не предусмотрено. Общее для всех условние задано в __init__\n",
    "\n",
    "- `validation` - возможность использовать валидацию в построении/отборе признаков. Можно не передавать. На текущий момент используется для 1) отбора признаков по p-value при построении стат модели\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "auto_woe.fit(train[features + ['target']], \n",
    "             target_name=\"target\",\n",
    "             features_type=features_type,\n",
    "             group_kf=None,\n",
    "             max_bin_count=max_bin_count,\n",
    "             features_monotone_constraints=features_monotone_constraints,\n",
    "             validation=test\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pred = auto_woe.predict_proba(test)\n",
    "roc_auc_score(test['target'], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = auto_woe.predict_proba(test[['number_72']], report=False)\n",
    "roc_auc_score(test['target'], pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(auto_woe.get_sql_inference_query('table'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Полезные методы модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `private_features_type` - типизация признаков\n",
    "- `get_woe` - рабиение на бины и WoE значения в них\n",
    "- `get_split` - границы разбиения. Особо полезен для категориальных признаков\n",
    "\n",
    "\n",
    "##### Замечание: \n",
    "ReportDeco - обертка для построения отчета. Она не обязательна для обучения и применения модели, но обязательна для построения отчета (см последнюю ячейку).\n",
    "Для доступа к атрибутам самой модели необходимо обратится к атрибуту auto_woe.model декоратора\n",
    "Все атрибуты объекта-модели так же доступны через объект-отчета.\n",
    "Однако в пикл отчета будет весить существенно больше, так что для сохранения модели на инференс стоит сохранять только auto_woe.model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Формирование отчета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_params = {\"automl_date_column\": \"report_month\", # колонка с датой в формате params['datetimeFormat']\n",
    "                 \"output_path\": \"./AUTOWOE_REPORT_1\", # папка, куда сгенерится отчет и сложатся нужные файлы\n",
    "                 \"report_name\": \"___НАЗВАНИЕ ОТЧЕТА___\",\n",
    "                 \"report_version_id\": 1,\n",
    "                 \"city\": \"Воронеж\",\n",
    "                 \"model_aim\": \"___ЦЕЛЬ ПОСТРОЕНИЯ МОДЕЛИ___\",\n",
    "                 \"model_name\": \"___НАЗВАНИЕ МОДЕЛИ___\",\n",
    "                 \"zakazchik\": \"___ЗАКАЗЧИК___\",\n",
    "                 \"high_level_department\": \"___ПОДРАЗДЕЛЕНИЕ___\",\n",
    "                 \"ds_name\": \"___РАЗРАБОТЧИК МОДЕЛИ___\",\n",
    "                 \"target_descr\": \"___ОПИСАНИЕ ЦЕЛЕВОГО СОБЫТИЯ___\",\n",
    "                 \"non_target_descr\": \"___ОПИСАНИЕ НЕЦЕЛЕВОГО СОБЫТИЯ___\"}\n",
    "\n",
    "auto_woe.generate_report(report_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "stem_cell": {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
